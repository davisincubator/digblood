{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "\n",
    "Workflow adapted from Katie Malone's [Workflows in Python](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/) series\n",
    "\n",
    "1. [Load data](#Load-Data)\n",
    "2. [Transform features and labels to conform to machine learning](#Transform-data-for-machine-learning)\n",
    "  1. _Note: need to incorporate Abbie's outlier data cleaning_\n",
    "3. [Make a train/test split (for cross validation score)](http://localhost:8889/notebooks/DataScience/digblood/notebooks/jfa-2.0-data%20pipeline.ipynb#Split-the-data-into-training/test-sets-by-hand)\n",
    "4. [Pick a classifer & evaluate it](#Playing-around-with-different-classifiers)\n",
    "5. [Evaluate several models](#Shortcut:-sklearn.model_selection.cross_val_score)\n",
    "\n",
    "\n",
    "----\n",
    "See also\n",
    "- [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Months since Last Donation</th>\n",
       "      <th>Number of Donations</th>\n",
       "      <th>Total Volume Donated (c.c.)</th>\n",
       "      <th>Months since First Donation</th>\n",
       "      <th>Made Donation in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>335</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1750</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>736</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>11500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Months since Last Donation  Number of Donations  \\\n",
       "0         619                           2                   50   \n",
       "1         664                           0                   13   \n",
       "2         441                           1                   16   \n",
       "3         160                           2                   20   \n",
       "4         358                           1                   24   \n",
       "5         335                           4                    4   \n",
       "6          47                           2                    7   \n",
       "7         164                           1                   12   \n",
       "8         736                           5                   46   \n",
       "9         436                           0                    3   \n",
       "\n",
       "   Total Volume Donated (c.c.)  Months since First Donation  \\\n",
       "0                        12500                           98   \n",
       "1                         3250                           28   \n",
       "2                         4000                           35   \n",
       "3                         5000                           45   \n",
       "4                         6000                           77   \n",
       "5                         1000                            4   \n",
       "6                         1750                           14   \n",
       "7                         3000                           35   \n",
       "8                        11500                           98   \n",
       "9                          750                            4   \n",
       "\n",
       "   Made Donation in March 2007  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            0  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            0  \n",
       "8                            1  \n",
       "9                            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir      = '../data/raw/'\n",
    "data_filename = 'blood_train.csv'\n",
    "df_blood      = pd.read_csv(data_dir+data_filename)\n",
    "\n",
    "df_blood.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Transform data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_blood.as_matrix()\n",
    "y = list(df_blood[\"Made Donation in March 2007\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Split the data into training/test sets by hand\n",
    "\n",
    "__Note: I don't actually use this data, since I overwrite using an automated way later on__\n",
    "\n",
    "Splits the 1st third of the data into the training set, the 2nd third "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows:\t 576\n",
      "Training rows:\t\t 0 - 192\n",
      "Validation rows:\t 192 - 384\n",
      "Testing rows:\t\t 384 - 576\n"
     ]
    }
   ],
   "source": [
    "# Split data into 4 partitions\n",
    "#  - training set\n",
    "#  - validation set\n",
    "#  - combined training & validation set\n",
    "#  - testing set\n",
    "\n",
    "nrows_total = df_blood.count()[1]\n",
    "nrows_train = int(nrows_total/3)\n",
    "nrows_valid = int(nrows_total*2/3)\n",
    "\n",
    "X_train, y_train             = X[:nrows_train]           , y[:nrows_train]\n",
    "X_valid, y_valid             = X[nrows_train:nrows_valid], y[nrows_train:nrows_valid]\n",
    "X_test , y_test              = X[nrows_valid:]           , y[nrows_valid:]\n",
    "X_train_valid, y_train_valid = X[:nrows_valid]           , y[:nrows_valid]\n",
    "\n",
    "print(\"Total number of rows:\\t\", nrows_total)\n",
    "print(\"Training rows:\\t\\t\"     , 0          ,\"-\", nrows_train)\n",
    "print(\"Validation rows:\\t\"     , nrows_train,\"-\", nrows_valid)\n",
    "print(\"Testing rows:\\t\\t\"      ,nrows_valid ,\"-\" , nrows_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Automated way to split data: \n",
    "### `sklearn.model_selection.train_test_split`\n",
    "\n",
    "Split the total dataset into training and testing sets via random selection\n",
    " - `test_size` - proportion of the dataset to put into the __test__ set\n",
    " - `randome_state` - Seed for pseudo-random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Rows in training set:\t 288\n",
      "No. Rows in testing set:\t 288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= sklearn.model_selection.train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.5, \n",
    "    random_state=0) \n",
    "\n",
    "print(\"No. Rows in training set:\\t\", len(X_train))\n",
    "print(\"No. Rows in testing set:\\t\" , len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Playing around with different classifiers\n",
    "\n",
    "With the data loaded, transformed and split, can now pass it into different classifiers and see how they perform\n",
    "\n",
    "Basic workflow for each classifier:\n",
    " 1. import classifier\n",
    " 2. initialize classifier into `clf` variable\n",
    " 3. fit data (`X_train`, `y_train`) into classifier\n",
    " 4. predict output (i.e. probabilities) using `X_test` data\n",
    " 5. evaluate prediction quality (via `sklearn.metrics.log_loss` function & `y_test` data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier: \n",
    "- [`sklearn.linear_model.LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "  - Example: [Simple linear regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest Classifier\n",
    "`sklearn.ensemble.RandomForestClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss score:\t 0.0226022615147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train uncalibrated random forest classifier \n",
    "# on whole train and validation data \n",
    "# and evaluate on test data\n",
    "clf       = sklearn.ensemble.RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Test/Evaluate the the model\n",
    "score     = sklearn.metrics.log_loss(y_test, clf_probs)\n",
    "print(\"Log-loss score:\\t\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated Random Forest Classifier\n",
    "- `sklearn.calibration.CalibratedClassifierCV`\n",
    "- `sklearn.ensemble.RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss score:\t 0.0208181404669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train random forest classifier\n",
    "#  - calibrate on validation data\n",
    "#  - evaluate test data\n",
    "clf       = sklearn.ensemble.RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Pass the RandomForestClassifier into the CalibrationClassifier\n",
    "sig_clf   = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(X_valid, y_valid)\n",
    "\n",
    "# Get prediction probabilities from model\n",
    "sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "\n",
    "# Test quality of predictions using `log_loss` function\n",
    "sig_score     = sklearn.metrics.log_loss(y_test, sig_clf_probs)\n",
    "print(\"Log-loss score:\\t\", sig_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Shortcut: `sklearn.model_selection.cross_val_score`\n",
    "\n",
    "From Katie Malone's [Workflows in Python](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/):\n",
    "> The cheapest and easiest way to train on one portion of my dataset and test on another, and to get a measure of model quality at the same time, is to use [sklearn.cross_validation.cross_val_score()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). \n",
    ">\n",
    "> `cross_val_score()` \n",
    "> - splits data into 3 equal portions\n",
    "> - trains on 2 portions\n",
    "> - tests on the third \n",
    ">\n",
    "> This process repeats 3 times. Thatâ€™s why 3 numbers get printed in the code block below.\n",
    "\n",
    "### Note: `log_loss` results are negative and is labelled `neg_log_loss` for the `cross_val_score` function\n",
    "\n",
    "See:\n",
    "- [Sklearn | Quantifying the Quality of Predictions](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- [StackOverflow | Why is log_loss negative?](http://stackoverflow.com/questions/26282884/why-is-the-logloss-negative)\n",
    "  - Basically, _higher score means better performance (less loss)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "- X: Training vector\n",
    "- y: Target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_blood.as_matrix()\n",
    "y = list(df_blood[\"Made Donation in March 2007\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05211964 -0.03698339 -0.04242597]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf   = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.model_selection.cross_val_score( \n",
    "    clf, \n",
    "    X, y,\n",
    "    scoring=\"neg_log_loss\")\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -9.99200722e-16  -9.99200722e-16  -9.99200722e-16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf   = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.model_selection.cross_val_score( \n",
    "    clf, \n",
    "    X, y,\n",
    "    scoring=\"neg_log_loss\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03331336 -0.04324528 -0.01836764]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf   = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.model_selection.cross_val_score( \n",
    "    clf, \n",
    "    X, y,\n",
    "    scoring=\"neg_log_loss\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Sources\n",
    "\n",
    "Examples:\n",
    "- [Example: Probability Calibration](http://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_multiclass.html#sphx-glr-auto-examples-calibration-plot-calibration-multiclass-py)\n",
    "  - _helpful for seeing whole workflow in action from loading to plotting_\n",
    "  \n",
    "Documentation\n",
    "- [sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- [sklearn.model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [sklearn.metrics.log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss)\n",
    "\n",
    "Discussion\n",
    "- [CrossValidated | sklearn `predict_proba` output interpretation](http://stats.stackexchange.com/questions/179977/scikit-predict-proba-output-interpretation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
