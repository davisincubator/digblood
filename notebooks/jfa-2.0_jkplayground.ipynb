{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "\n",
    "Workflow adapted from Katie Malone's [Workflows in Python](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/) series\n",
    "\n",
    "1. [Load data](#Load-Data)\n",
    "2. [Transform data to conform to sklearn functions](#Transform-data-for-machine-learning)\n",
    "  1. _Note: need to incorporate Abbie's outlier data cleaning_\n",
    "3. [Split training data into train/test sets for cross validation](#Split-data-into-training/test-sets-for-cross-validation)\n",
    "4. [Pick a classifer & evaluate it](#Playing-around-with-different-classifiers)\n",
    "5. [Creating CSV-file for submission](#Submission-code-for-Logistic-Regression)\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "-----\n",
    "See also\n",
    "- Playing around w/ other models besides Logistic Regression\n",
    "  - [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "  - [Calibrated Random Forest Classifier](#Calibrated-Random-Forest-Classifier)\n",
    "- [Playing around w/ `sklearn.model_selection.cross_val_score` function](#Playing-around-w/:-sklearn.model_selection.cross_val_score)\n",
    "  - [Logistic Regression](#LogisticRegression)\n",
    "  - [DecisionTreeClassifier](#DecisionTreeClassifier)\n",
    "  - [RandomForestClassifier](#RandomForestClassifier)\n",
    "- [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Months since Last Donation</th>\n",
       "      <th>Number of Donations</th>\n",
       "      <th>Total Volume Donated (c.c.)</th>\n",
       "      <th>Months since First Donation</th>\n",
       "      <th>Made Donation in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>335</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1750</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>736</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>11500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Months since Last Donation  Number of Donations  \\\n",
       "0         619                           2                   50   \n",
       "1         664                           0                   13   \n",
       "2         441                           1                   16   \n",
       "3         160                           2                   20   \n",
       "4         358                           1                   24   \n",
       "5         335                           4                    4   \n",
       "6          47                           2                    7   \n",
       "7         164                           1                   12   \n",
       "8         736                           5                   46   \n",
       "9         436                           0                    3   \n",
       "\n",
       "   Total Volume Donated (c.c.)  Months since First Donation  \\\n",
       "0                        12500                           98   \n",
       "1                         3250                           28   \n",
       "2                         4000                           35   \n",
       "3                         5000                           45   \n",
       "4                         6000                           77   \n",
       "5                         1000                            4   \n",
       "6                         1750                           14   \n",
       "7                         3000                           35   \n",
       "8                        11500                           98   \n",
       "9                          750                            4   \n",
       "\n",
       "   Made Donation in March 2007  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            0  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            0  \n",
       "8                            1  \n",
       "9                            0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir      = '../data/raw/'\n",
    "data_filename = 'blood_train.csv'\n",
    "df_blood      = pd.read_csv(data_dir+data_filename)\n",
    "\n",
    "df_blood.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "----\n",
    "# Transform data for machine learning\n",
    "\n",
    " - Used `iloc` to drop the subject id column and the prediction column (i.e. 'Made Donation in March 2007')\n",
    "   - _Previously, forgot to drop the 'Made Donation in March 2007' column and totally overfitted the data #LessonLearned_\n",
    " - Converted to matrix array format for input into `predict_proba`, `train_test_split` functions\n",
    " - Saved the predictions in a separate array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_blood.iloc[:,1:5].as_matrix()\n",
    "y = list(df_blood[\"Made Donation in March 2007\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log transform the features\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p)\n",
    "X= transformer.transform(X)\n",
    "\n",
    "# Normalize the features using Standard Scalar\n",
    "#X_test = sklearn.preprocessing.StandardScaler().fit_transform(X_test)\n",
    "#X_train = sklearn.preprocessing.StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "----\n",
    "#  Split data into training/test sets for cross-validation\n",
    "### `sklearn.model_selection.train_test_split`\n",
    "\n",
    "Split the total dataset into training and testing sets via random selection\n",
    " - `test_size` - proportion of the dataset to put into the __test__ set\n",
    " - `randome_state` - Seed for pseudo-random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No. Rows in training set:\\t', 288)\n",
      "('No. Rows in testing set:\\t', 288)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= sklearn.model_selection.train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.5, \n",
    "    random_state=0) \n",
    "\n",
    "print(\"No. Rows in training set:\\t\", len(X_train))\n",
    "print(\"No. Rows in testing set:\\t\" , len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "----\n",
    "### Cross-validation: Split the data into training/test sets by hand\n",
    "\n",
    "__Note: I don't actually use this data, since I used `train_test_split()`__\n",
    "\n",
    "Splits the 1st third of the data into the training set, the 2nd third into validation set, last 3rd into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into 4 partitions\n",
    "#  - training set\n",
    "#  - validation set\n",
    "#  - combined training & validation set\n",
    "#  - testing set\n",
    "\n",
    "# nrows_total = df_blood.count()[1]\n",
    "# nrows_train = int(nrows_total/3)\n",
    "# nrows_valid = int(nrows_total*2/3)\n",
    "\n",
    "# X_train, y_train             = X[:nrows_train]           , y[:nrows_train]\n",
    "# X_valid, y_valid             = X[nrows_train:nrows_valid], y[nrows_train:nrows_valid]\n",
    "# X_test , y_test              = X[nrows_valid:]           , y[nrows_valid:]\n",
    "# X_train_valid, y_train_valid = X[:nrows_valid]           , y[:nrows_valid]\n",
    "\n",
    "# print(\"Total number of rows:\\t\", nrows_total)\n",
    "# print(\"Training rows:\\t\\t\"     , 0          ,\"-\", nrows_train)\n",
    "# print(\"Validation rows:\\t\"     , nrows_train,\"-\", nrows_valid)\n",
    "# print(\"Testing rows:\\t\\t\"      ,nrows_valid ,\"-\" , nrows_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "----\n",
    "# Playing around with different classifiers\n",
    "\n",
    "With the data loaded, transformed and split, can now pass it into different classifiers and see how they perform\n",
    "\n",
    "Basic workflow for each classifier:\n",
    " 1. import classifier\n",
    " 2. initialize classifier into `clf` variable\n",
    " 3. fit data (`X_train`, `y_train`) into classifier\n",
    " 4. predict output (i.e. probabilities) using `X_test` data\n",
    " 5. evaluate prediction quality (via `sklearn.metrics.log_loss` function & `y_test` data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier: \n",
    "- [`sklearn.linear_model.LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "  - Example: [Simple linear regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 0.46686030610135276)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf       = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "\n",
    "score     = sklearn.metrics.log_loss(y_test, clf_probs)\n",
    "print(\"Log-loss score:\\t\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 0.49254144740610439)\n"
     ]
    }
   ],
   "source": [
    "clfE       = sklearn.linear_model.ElasticNet(l1_ratio=0.24)\n",
    "clfE.fit(X_train, y_train)\n",
    "\n",
    "clfE_probs = clfE.predict(X_test)\n",
    "\n",
    "score     = sklearn.metrics.log_loss(y_test, clfE_probs)\n",
    "print(\"Log-loss score:\\t\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 0.46686030610135276)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfL       = sklearn.linear_model.LogisticRegression(C=1)\n",
    "clfL.fit(X_train, y_train)\n",
    "\n",
    "clfL_probs = clfL.predict_proba(X_test)\n",
    "\n",
    "score     = sklearn.metrics.log_loss(y_test, clfL_probs)\n",
    "print(\"Log-loss score:\\t\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 0.53195276047172257)\n"
     ]
    }
   ],
   "source": [
    "clfECV       = sklearn.linear_model.ElasticNetCV(l1_ratio=0.24)\n",
    "clfECV.fit(X_train, y_train)\n",
    "\n",
    "clfECV_probs = clfECV.predict(X_test)\n",
    "score     = sklearn.metrics.log_loss(y_test, clfECV_probs )\n",
    "print(\"Log-loss score:\\t\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_preprocess_data',\n",
       " '_set_intercept',\n",
       " 'alpha_',\n",
       " 'alphas',\n",
       " 'alphas_',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'cv',\n",
       " 'decision_function',\n",
       " 'dual_gap_',\n",
       " 'eps',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'l1_ratio',\n",
       " 'l1_ratio_',\n",
       " 'max_iter',\n",
       " 'mse_path_',\n",
       " 'n_alphas',\n",
       " 'n_iter_',\n",
       " 'n_jobs',\n",
       " 'normalize',\n",
       " 'path',\n",
       " 'positive',\n",
       " 'precompute',\n",
       " 'predict',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'selection',\n",
       " 'set_params',\n",
       " 'tol',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(clfECV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Submission code for Logistic Regression\n",
    "\n",
    "- Results saved in: `/data/processed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Test Data\n",
    "data_filename = 'blood_test.csv'\n",
    "df_test       = pd.read_csv(data_dir+data_filename)\n",
    "\n",
    "# Transform data\n",
    "#  - dropped the ID column\n",
    "#  - converted to matrix array for input to `predict_proba`\n",
    "Z             = df_test.iloc[:,1:5].as_matrix()\n",
    "\n",
    "# Predict data\n",
    "clf_probs     = clf.predict_proba(Z)\n",
    "\n",
    "# Add predictions back into test data frame\n",
    "df_test['Made Donation in March 2007'] = clf_probs[:,1]\n",
    "df_test.head()\n",
    "\n",
    "# Setup save filename and directory\n",
    "submit_dir      = '../data/processed/'\n",
    "submit_filename = 'submit-logistic_regression.csv'\n",
    "\n",
    "# Save to CSV-file using only the subject-id, and predition columns\n",
    "df_test.to_csv(submit_dir+submit_filename, \n",
    "               columns=('Unnamed: 0', 'Made Donation in March 2007'),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest Classifier\n",
    "`sklearn.ensemble.RandomForestClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 1.1349310694085468)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train uncalibrated random forest classifier \n",
    "# on whole train and validation data \n",
    "# and evaluate on test data\n",
    "clf       = sklearn.ensemble.RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Test/Evaluate the the model\n",
    "score     = sklearn.metrics.log_loss(y_test, clf_probs)\n",
    "print(\"Log-loss score:\\t\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated Random Forest Classifier\n",
    "- `sklearn.calibration.CalibratedClassifierCV`\n",
    "- `sklearn.ensemble.RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 0.80482654902433792)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train random forest classifier\n",
    "#  - calibrate on validation data\n",
    "#  - evaluate test data\n",
    "clf       = sklearn.ensemble.RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Pass the RandomForestClassifier into the CalibrationClassifier\n",
    "sig_clf   = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get prediction probabilities from model\n",
    "sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "\n",
    "# Test quality of predictions using `log_loss` function\n",
    "sig_score     = sklearn.metrics.log_loss(y_test, sig_clf_probs)\n",
    "print(\"Log-loss score:\\t\", sig_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier\n",
    "- `sklearn.svm.SVC`\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log-loss score:\\t', 0.55300082892047209)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = []\n",
    "clf_probs = []\n",
    "# clf = svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "#     max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "#     tol=0.001, verbose=False)\n",
    "# clf = svm.SVC(kernel='rbf',degree=2, probability=True)\n",
    "#StandardScaler\n",
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(X_trainNorm, y_train) \n",
    "\n",
    "# Get prediction probabilities from model\n",
    "clf_probs = clf.predict_proba(X_testNorm)\n",
    "\n",
    "# Test quality of predictions using `log_loss` function\n",
    "score     = sklearn.metrics.log_loss(y_test, clf_probs)\n",
    "print(\"Log-loss score:\\t\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    8 2000   38]\n",
      " [   2   11 2750   79]\n",
      " [   2    5 1250   63]\n",
      " ..., \n",
      " [  11    6 1500   41]\n",
      " [   2    7 1750   76]\n",
      " [   4    5 1250   28]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "----\n",
    "# Playing around w/: `sklearn.model_selection.cross_val_score`\n",
    "\n",
    "From Katie Malone's [Workflows in Python](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/):\n",
    "> The cheapest and easiest way to train on one portion of my dataset and test on another, and to get a measure of model quality at the same time, is to use [sklearn.cross_validation.cross_val_score()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). \n",
    ">\n",
    "> `cross_val_score()` \n",
    "> - splits data into 3 equal portions\n",
    "> - trains on 2 portions\n",
    "> - tests on the third \n",
    ">\n",
    "> __This process repeats 3 times. Thatâ€™s why 3 numbers get printed in the code block below.__\n",
    "\n",
    "### Note: `log_loss` results are negative and is labelled `neg_log_loss` for the `cross_val_score` function\n",
    "\n",
    "See:\n",
    "- [Sklearn | Quantifying the Quality of Predictions](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- [StackOverflow | Why is log_loss negative?](http://stackoverflow.com/questions/26282884/why-is-the-logloss-negative)\n",
    "  - Basically, _higher score means better performance (less loss)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "- X: Training vector\n",
    "- y: Target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_blood.iloc[:,1:5].as_matrix()\n",
    "y = list(df_blood[\"Made Donation in March 2007\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56947507 -0.54819823 -0.48901389]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf   = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.model_selection.cross_val_score( \n",
    "    clf, \n",
    "    X, y,\n",
    "    scoring=\"neg_log_loss\")\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.08570262  -7.84956205  -8.54322446]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf   = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.model_selection.cross_val_score( \n",
    "    clf, \n",
    "    X, y,\n",
    "    scoring=\"neg_log_loss\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.82437783 -5.49929871 -1.66941622]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf   = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.model_selection.cross_val_score( \n",
    "    clf, \n",
    "    X, y,\n",
    "    scoring=\"neg_log_loss\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "----\n",
    "# Sources\n",
    "\n",
    "Examples:\n",
    "- [Example: Probability Calibration](http://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_multiclass.html#sphx-glr-auto-examples-calibration-plot-calibration-multiclass-py)\n",
    "  - _helpful for seeing whole workflow in action from loading to plotting_\n",
    "  \n",
    "Documentation\n",
    "- [sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- [sklearn.model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [sklearn.metrics.log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss)\n",
    "\n",
    "Discussion\n",
    "- [CrossValidated | sklearn `predict_proba` output interpretation](http://stats.stackexchange.com/questions/179977/scikit-predict-proba-output-interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
